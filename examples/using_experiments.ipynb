{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using PyQCS Experiments\n",
    "\n",
    "Quantum simulations can take quite a while: Applying gates to states takes some time (this time grows exponentially in the number of qbits), and often many samples are required to measure amplitudes with sufficient precision. A typical case is the simulation of Hamiltonian dynamics using trotterization: There are several qbits, deep circuits, and sampling. But we also want to repeat the simulation for several points in time.\n",
    "\n",
    "The subpackage `pyqcs.experiment` allows for a simple way to parallelize such simulations and run them on clusters using [ray](https://pypi.org/project/ray/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelized Hamiltonian Dynamics\n",
    "\n",
    "To demonstrate the parallelization we will use a simple example of Hamiltonian dynamics: The transverse Ising model in a magnetic field with open boundary conditions. For the Hamiltonian\n",
    "\n",
    "$$ H = \\sum\\limits_{i=0}^{n-2} Z_iZ_{i+1} + g\\sum\\limits_{i=0}^{n-1} X_i $$\n",
    "\n",
    "we can derive the following Trotterized transfer matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyqcs import X, Z, H, R, CX, State, list_to_circuit, sample\n",
    "\n",
    "def T_interaction(a, b, t):\n",
    "    theta = -t/2\n",
    "\n",
    "    return (CX(a, b) | R(a, -theta)\n",
    "            | X(a) | R(a, theta) | X(a) | CX(a, b))\n",
    "\n",
    "def T_field(a, t, g):\n",
    "    theta = g*t/2\n",
    "\n",
    "    return (H(a) | R(a, -2*theta) | H(a)\n",
    "            | R(a, theta) | X(a) | R(a, theta) | X(a))\n",
    "\n",
    "def T_time_slice(qbits, t, g, N):\n",
    "    interactions_half = list_to_circuit(\n",
    "                [T_interaction(i, i+1, t/(2*N))\n",
    "                    for i,_ in enumerate(qbits[:-1])]\n",
    "            )\n",
    "\n",
    "    field = list_to_circuit([T_field(i, t/N, g) for i,_ in enumerate(qbits)])\n",
    "\n",
    "    return (interactions_half | field | interactions_half)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run the simulation using $6$ sites, with a magnetic fieldstrength of $g = 3$,\n",
    "$80$ Trotterization steps, $\\Delta t = 0.1$, and a final time of $t_s = 29$. We will measure the amplitude of\n",
    "the second site and use $2200$ samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nqbits = 6\n",
    "g = 3\n",
    "N_trot = 80\n",
    "t_stop = 29\n",
    "delta_t = 0.1\n",
    "qbits = list(range(nqbits))\n",
    "\n",
    "n_sample = 4200\n",
    "measure = 0b10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_coefficient_mask = [False if (i & measure) else True for i in range(2**nqbits)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build a workflow to compute the probability amplitude at time $t$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyqcs.experiment.workflow import FunctionInstruction, WorkflowSpawner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_state(t):\n",
    "    state = State.new_zero_state(nqbits)\n",
    "\n",
    "    T_dt = T_time_slice(qbits, t, g, N_trot)\n",
    "    for _ in range(N_trot):\n",
    "        state = T_dt * state\n",
    "        \n",
    "    return state\n",
    "\n",
    "def sample_result(state):\n",
    "    result = sample(state, measure, n_sample)\n",
    "    return result[0] / n_sample\n",
    "\n",
    "instructions = [\n",
    "    FunctionInstruction(\"Simulate Dynamics\", simulate_state)\n",
    "    , FunctionInstruction(\"Sample the Probability Amplitude\", sample_result)\n",
    "]\n",
    "\n",
    "wf_spawner = WorkflowSpawner(\"Transition Probability Simulation\", instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A workflow always has a list of instructions: These are callable (in the most simple case just functions), take the result of the previous instruction, and return the input for the next instruction. The first instruction takes the parameters of the workflow; the last instruction returns the final result.\n",
    "\n",
    "Using `FunctionInstruction` to wrap a function has advantages when logging is turned on.\n",
    "\n",
    "The `WorkFlowSpawner` is a helper that will create a new `Workflow` using the `spawn` method. This is needed because `ray` requires several actors for parallelization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use this workflow to create an `ActorPool` using `ray` and compute the transition amplitudes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-06 17:35:19,821\tINFO worker.py:634 -- Connecting to existing Ray cluster at address: 132.199.38.122:6379\n",
      "2020-10-06 17:35:20,516\tWARNING services.py:208 -- Some processes that the driver needs to connect to have not registered with Redis, so retrying. Have you run 'ray start' on this node?\n",
      "2020-10-06 17:35:22,155\tWARNING services.py:208 -- Some processes that the driver needs to connect to have not registered with Redis, so retrying. Have you run 'ray start' on this node?\n",
      "2020-10-06 17:35:23,713\tWARNING services.py:208 -- Some processes that the driver needs to connect to have not registered with Redis, so retrying. Have you run 'ray start' on this node?\n",
      "2020-10-06 17:35:25,438\tWARNING services.py:208 -- Some processes that the driver needs to connect to have not registered with Redis, so retrying. Have you run 'ray start' on this node?\n",
      "2020-10-06 17:35:26,990\tWARNING services.py:208 -- Some processes that the driver needs to connect to have not registered with Redis, so retrying. Have you run 'ray start' on this node?\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Redis has started but no raylets have registered yet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a72c2a74bbf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#ray.init() # Connect to your cluster in this step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'132.199.38.122:6379'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_redis_password\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'5241590000000000'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnworkers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;31m# Use something that matches your CPU count here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.envs/pyqcs/lib/python3.7/site-packages/ray/worker.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(address, num_cpus, num_gpus, resources, object_store_memory, local_mode, ignore_reinit_error, include_dashboard, dashboard_host, dashboard_port, job_config, configure_logging, logging_level, logging_format, log_to_driver, _enable_object_reconstruction, _redis_max_memory, _plasma_directory, _node_ip_address, _driver_object_store_memory, _memory, _redis_password, _java_worker_options, _code_search_path, _temp_dir, _load_code_from_local, _lru_evict, _metrics_export_port, _object_spilling_config, _system_config)\u001b[0m\n\u001b[1;32m    740\u001b[0m             \u001b[0mshutdown_at_exit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m             \u001b[0mspawn_reaper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m             connect_only=True)\n\u001b[0m\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m     connect(\n",
      "\u001b[0;32m~/.envs/pyqcs/lib/python3.7/site-packages/ray/node.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ray_params, head, shutdown_at_exit, spawn_reaper, connect_only)\u001b[0m\n\u001b[1;32m    159\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mredis_address\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raylet_ip_address\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                     redis_password=self.redis_password)\n\u001b[0m\u001b[1;32m    162\u001b[0m                 self._plasma_store_socket_name = address_info[\n\u001b[1;32m    163\u001b[0m                     \"object_store_address\"]\n",
      "\u001b[0;32m~/.envs/pyqcs/lib/python3.7/site-packages/ray/services.py\u001b[0m in \u001b[0;36mget_address_info_from_redis\u001b[0;34m(redis_address, node_ip_address, num_retries, redis_password)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m             return get_address_info_from_redis_helper(\n\u001b[0;32m--> 201\u001b[0;31m                 redis_address, node_ip_address, redis_password=redis_password)\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnum_retries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.envs/pyqcs/lib/python3.7/site-packages/ray/services.py\u001b[0m in \u001b[0;36mget_address_info_from_redis_helper\u001b[0;34m(redis_address, node_ip_address, redis_password)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrelevant_client\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         raise RuntimeError(\n\u001b[0;32m--> 184\u001b[0;31m             \"Redis has started but no raylets have registered yet.\")\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     return {\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Redis has started but no raylets have registered yet."
     ]
    }
   ],
   "source": [
    "import ray\n",
    "#ray.init() # Connect to your cluster in this step.\n",
    "ray.init(address='132.199.38.122:6379', _redis_password='5241590000000000')\n",
    "\n",
    "nworkers = 4 # Use something that matches your CPU count here.\n",
    "\n",
    "actors = [wf_spawner.spawn() for _ in range(nworkers)]\n",
    "pool = ray.util.ActorPool(actors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use this pool to compute the values as a function of time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "time = np.arange(0, t_stop, delta_t)\n",
    "\n",
    "results = np.array(list(pool.map(lambda a,v: a.execute.remote(v), time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(time, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that one should estimate the errors on these values but we omit this step."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
